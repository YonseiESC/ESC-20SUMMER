{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Week4_HW_최정윤.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ARXpift3sY",
        "colab_type": "text"
      },
      "source": [
        "# VGG & ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw3fXIIlt3sc",
        "colab_type": "text"
      },
      "source": [
        "## 1. VGG 19 - CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMI9U4ft3sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33j3Tkwgu9wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXdpgjHqvNVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5c47ecd1-fab7-476a-b3eb-89e905dcf80e"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDfD1MVkvise",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models.vgg as vgg"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8oTQJLBvoXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tafg0x8vvoC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        #self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz36PYQqvv3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg19= VGG(vgg.make_layers(cfg),10,True).to(device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twzPgVYEv34v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(vgg19.parameters(), lr = 0.005,momentum=0.9)\n",
        "\n",
        "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBjZ3ocWv1sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e007df4-e042-4d9d-85e8-75884f968605"
      },
      "source": [
        "a=torch.Tensor(1,3,32,32).to(device)\n",
        "out = vgg19(a)\n",
        "print(out)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0764,  0.0401, -0.0824, -0.0515, -0.0517,  0.0340,  0.0042, -0.0122,\n",
            "         -0.0214,  0.0268]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHeCTd3Kv8n0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "45bb1b72-0aaa-4d78-b838-532164cb7eab"
      },
      "source": [
        "print(len(trainloader))\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    lr_sche.step()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = vgg19(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 30 == 29:    # print every 30 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 30))\n",
        "            running_loss = 0.0\n",
        "        \n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n",
            "[1,    30] loss: 2.303\n",
            "[1,    60] loss: 2.303\n",
            "[1,    90] loss: 2.303\n",
            "[2,    30] loss: 2.303\n",
            "[2,    60] loss: 2.302\n",
            "[2,    90] loss: 2.302\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_u-8v_K258F",
        "colab_type": "text"
      },
      "source": [
        "## 2. ResNet 34 - CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9h05k5w26vH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "157a6de3-4cbb-4aa5-d93c-43fcb93a8ea6"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
        "\n",
        "print(trainset.data.shape)\n",
        "\n",
        "train_data_mean = trainset.data.mean( axis=(0,1,2) )\n",
        "train_data_std = trainset.data.std( axis=(0,1,2) )\n",
        "\n",
        "\n",
        "print(train_data_mean)\n",
        "print(train_data_std)\n",
        "\n",
        "train_data_mean = train_data_mean / 255\n",
        "train_data_std = train_data_std / 255\n",
        "\n",
        "print(train_data_mean)\n",
        "print(train_data_std)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n",
            "[125.30691805 122.95039414 113.86538318]\n",
            "[62.99321928 62.08870764 66.70489964]\n",
            "[0.49139968 0.48215841 0.44653091]\n",
            "[0.24703223 0.24348513 0.26158784]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJHYT5XV3Np8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fa1c05df-592c-44f5-d462-e85ba34b3b49"
      },
      "source": [
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_data_mean, train_data_std)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(train_data_mean, train_data_std)\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XHhc-zh3QER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models.resnet as resnet"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_fI9SS83R5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1x1=resnet.conv1x1\n",
        "Bottleneck = resnet.Bottleneck\n",
        "BasicBlock= resnet.BasicBlock"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycJOOHnE3Vm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        #x.shape =[1, 16, 32,32]\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        #x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        #x.shape =[1, 128, 32,32]\n",
        "        x = self.layer2(x)\n",
        "        #x.shape =[1, 256, 32,32]\n",
        "        x = self.layer3(x)\n",
        "        #x.shape =[1, 512, 16,16]\n",
        "        x = self.layer4(x)\n",
        "        #x.shape =[1, 1024, 8,8]\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHCwQx5u3ZY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet34 = ResNet(resnet.BasicBlock, [3, 4, 6, 3], 10, True).to(device) "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v5TqBaT3aw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "28073abf-a8b8-441a-91af-c57ecfc6af48"
      },
      "source": [
        "a=torch.Tensor(1,3,32,32).to(device)\n",
        "out = resnet34(a)\n",
        "print(out)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0175,  0.1048,  0.1075, -0.1943,  0.1332,  0.0705, -0.0787,  0.1143,\n",
            "          0.0704,  0.0886]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BehNaYC53fL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(resnet34.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n",
        "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OehF28gA3i7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "38e81dc5-2692-4a79-e03f-4bd52d250f15"
      },
      "source": [
        "print(len(trainloader))\n",
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    lr_sche.step()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet34(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 30 == 29:    # print every 30 mini-batches      \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 30))\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196\n",
            "[1,    30] loss: 2.113\n",
            "[1,    60] loss: 1.901\n",
            "[1,    90] loss: 1.799\n",
            "[1,   120] loss: 1.705\n",
            "[1,   150] loss: 1.628\n",
            "[1,   180] loss: 1.572\n",
            "[2,    30] loss: 1.471\n",
            "[2,    60] loss: 1.409\n",
            "[2,    90] loss: 1.299\n",
            "[2,   120] loss: 1.265\n",
            "[2,   150] loss: 1.210\n",
            "[2,   180] loss: 1.151\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}